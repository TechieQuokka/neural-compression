#!/usr/bin/env python3
"""ìµœì†Œ ê¸°ëŠ¥ RTX 3060 ì••ì¶• ëª¨ë¸"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from pathlib import Path


class SimpleAutoEncoder(nn.Module):
    """ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ ì˜¤í† ì¸ì½”ë”"""
    
    def __init__(self, latent_dim=64):
        super().__init__()
        
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, 4, 2, 1),  # 128 -> 64
            nn.BatchNorm2d(32),
            nn.ReLU(),
            
            nn.Conv2d(32, 64, 4, 2, 1),  # 64 -> 32
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            nn.Conv2d(64, 128, 4, 2, 1),  # 32 -> 16
            nn.BatchNorm2d(128),
            nn.ReLU(),
            
            nn.Conv2d(128, 256, 4, 2, 1),  # 16 -> 8
            nn.BatchNorm2d(256),
            nn.ReLU(),
            
            nn.AdaptiveAvgPool2d(4),  # ê³ ì • í¬ê¸°ë¡œ ë§Œë“¤ê¸°
            nn.Flatten(),
            nn.Linear(256 * 4 * 4, latent_dim)
        )
        
        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 256 * 4 * 4),
            nn.ReLU(),
            nn.Unflatten(1, (256, 4, 4)),
            
            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # 4 -> 8
            nn.BatchNorm2d(128),
            nn.ReLU(),
            
            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 8 -> 16
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            nn.ConvTranspose2d(64, 32, 4, 2, 1),  # 16 -> 32
            nn.BatchNorm2d(32),
            nn.ReLU(),
            
            nn.ConvTranspose2d(32, 16, 4, 2, 1),  # 32 -> 64
            nn.BatchNorm2d(16),
            nn.ReLU(),
            
            nn.ConvTranspose2d(16, 3, 4, 2, 1),  # 64 -> 128
            nn.Tanh()
        )
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self.apply(self._init_weights)
    
    def _init_weights(self, m):
        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):
            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.BatchNorm2d):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.Linear):
            nn.init.kaiming_normal_(m.weight)
            nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        latent = self.encoder(x)
        reconstructed = self.decoder(latent)
        return reconstructed, latent


def minimal_rtx3060_train():
    """ìµœì†Œ ê¸°ëŠ¥ RTX 3060 í›ˆë ¨"""
    
    print("ğŸš€ ìµœì†Œ ê¸°ëŠ¥ RTX 3060 ì••ì¶• ëª¨ë¸ í›ˆë ¨")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ë””ë°”ì´ìŠ¤: {device}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        torch.backends.cudnn.benchmark = True
    
    # ê°„ë‹¨í•œ ëª¨ë¸
    model = SimpleAutoEncoder(latent_dim=64).to(device)
    
    # CIFAR-10 ë°ì´í„°
    transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # [-1, 1] ë²”ìœ„
    ])
    
    dataset = datasets.CIFAR10(
        root='./data', 
        train=True, 
        download=True, 
        transform=transform
    )
    
    # RTX 3060 ìµœì í™” ë°ì´í„°ë¡œë”
    dataloader = DataLoader(
        dataset,
        batch_size=16,  # RTX 3060 12GBì— ì í•©
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        persistent_workers=True
    )
    
    # ì˜µí‹°ë§ˆì´ì €
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=1e-3,
        betas=(0.9, 0.999),
        eps=1e-8
    )
    
    print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
    print(f"ë°°ì¹˜ í¬ê¸°: {dataloader.batch_size}")
    
    # í›ˆë ¨ ë£¨í”„
    model.train()
    train_losses = []
    psnr_history = []
    best_psnr = 0.0
    
    epochs = 20
    
    for epoch in range(epochs):
        epoch_loss = 0.0
        epoch_psnr = 0.0
        num_batches = 0
        
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")
        
        for batch_idx, (images, _) in enumerate(pbar):
            if batch_idx >= 100:  # ì œí•œëœ ë°°ì¹˜ ìˆ˜
                break
            
            images = images.to(device, non_blocking=True)
            
            optimizer.zero_grad()
            
            # Forward pass
            reconstructed, latent = model(images)
            
            # ì†ì‹¤ ê³„ì‚°
            loss = F.mse_loss(reconstructed, images)
            
            # NaN ì²´í¬
            if torch.isnan(loss) or torch.isinf(loss):
                print(f"NaN ê°ì§€, ê±´ë„ˆë›°ê¸°")
                continue
            
            # Backward pass
            loss.backward()
            
            # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            
            optimizer.step()
            
            # PSNR ê³„ì‚°
            with torch.no_grad():
                mse = F.mse_loss(reconstructed, images)
                if mse > 0:
                    # ì •ê·œí™”ëœ ì´ë¯¸ì§€ì— ëŒ€í•œ PSNR ê³„ì‚°
                    psnr = 20 * torch.log10(2.0 / torch.sqrt(mse))  # [-1,1] ë²”ìœ„ì´ë¯€ë¡œ 2.0 ì‚¬ìš©
                    epoch_psnr += psnr.item()
            
            epoch_loss += loss.item()
            num_batches += 1
            
            pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'PSNR': f'{psnr.item():.2f}' if 'psnr' in locals() else 'N/A'
            })
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬
            if batch_idx % 20 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        if num_batches > 0:
            avg_loss = epoch_loss / num_batches
            avg_psnr = epoch_psnr / num_batches
            
            train_losses.append(avg_loss)
            psnr_history.append(avg_psnr)
            
            print(f"\nEpoch {epoch+1} ì™„ë£Œ:")
            print(f"  í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
            print(f"  í‰ê·  PSNR: {avg_psnr:.2f} dB")
            
            if torch.cuda.is_available():
                memory_used = torch.cuda.memory_allocated() / 1024**3
                print(f"  GPU ë©”ëª¨ë¦¬: {memory_used:.1f}GB")
            
            # ìµœê³  ì„±ëŠ¥ ì €ì¥
            if avg_psnr > best_psnr:
                best_psnr = avg_psnr
                checkpoint_dir = Path("checkpoints/minimal")
                checkpoint_dir.mkdir(parents=True, exist_ok=True)
                
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'loss': avg_loss,
                    'psnr': avg_psnr
                }, checkpoint_dir / f"best_minimal_model.pth")
                print(f"  âœ“ ìƒˆë¡œìš´ ìµœê³  PSNR: {avg_psnr:.2f} dB")
    
    print(f"\nğŸ¯ í›ˆë ¨ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœê³  PSNR: {best_psnr:.2f} dB")
    
    # ê²°ê³¼ ì‹œê°í™”
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(train_losses)
    plt.title('Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('MSE Loss')
    plt.grid(True)
    
    plt.subplot(1, 2, 2)
    plt.plot(psnr_history)
    plt.title('PSNR Progress')
    plt.xlabel('Epoch')
    plt.ylabel('PSNR (dB)')
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig('minimal_rtx3060_results.png', dpi=150, bbox_inches='tight')
    print("ğŸ“ˆ ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥: minimal_rtx3060_results.png")
    
    # ìµœì¢… í…ŒìŠ¤íŠ¸
    model.eval()
    with torch.no_grad():
        test_images, _ = next(iter(dataloader))
        test_images = test_images[:4].to(device)
        
        reconstructed, latent = model(test_images)
        
        print(f"\nğŸ“ ìµœì¢… í…ŒìŠ¤íŠ¸:")
        print(f"   ì…ë ¥ í˜•íƒœ: {test_images.shape}")
        print(f"   ì¶œë ¥ í˜•íƒœ: {reconstructed.shape}")
        
        mse = F.mse_loss(reconstructed, test_images)
        psnr = 20 * torch.log10(2.0 / torch.sqrt(mse))
        print(f"   ìµœì¢… PSNR: {psnr:.2f} dB")
        
        # ì••ì¶•ë¥  ê³„ì‚°
        original_bits = test_images.numel() * 32
        compressed_bits = latent.numel() * 32  # ì‹¤ì œë¡œëŠ” ì–‘ìí™”ë¡œ ë” ì‘ì•„ì§ˆ ìˆ˜ ìˆìŒ
        compression_ratio = original_bits / compressed_bits
        print(f"   ì••ì¶•ë¥ : {compression_ratio:.1f}:1")
        
        # ì‹œê°ì  ê²°ê³¼ ì €ì¥
        import torchvision.utils as vutils
        
        comparison = torch.cat([test_images[:4], reconstructed[:4]], dim=0)
        grid = vutils.make_grid(comparison, nrow=4, normalize=True, scale_each=True)
        vutils.save_image(grid, 'minimal_reconstruction_comparison.png')
        print("   ğŸ–¼ï¸  ì¬êµ¬ì„± ë¹„êµ ì´ë¯¸ì§€ ì €ì¥: minimal_reconstruction_comparison.png")
    
    print(f"\nâœ… RTX 3060 12GB ìµœì í™” ì™„ë£Œ!")
    print(f"   - ì•ˆì •ì ì¸ í›ˆë ¨ ì„±ê³µ")
    print(f"   - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì‚¬ìš©")
    print(f"   - í¬ê¸° ë¬¸ì œ í•´ê²°")


if __name__ == "__main__":
    minimal_rtx3060_train()