#!/usr/bin/env python3
"""RTX 3060 12GB í¬ê¸° ë¬¸ì œ í•´ê²°ëœ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent / "src"))

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
import os
from tqdm import tqdm

from neural_compression.models.vae_gan_compression import VAEGANCompression
from neural_compression.data.datasets import CIFARDataset
from neural_compression.data.transforms import CompressionTransforms


def initialize_weights(m):
    """ì•ˆì •ì ì¸ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
    if isinstance(m, (torch.nn.Conv2d, torch.nn.ConvTranspose2d)):
        torch.nn.init.xavier_normal_(m.weight, gain=0.02)
        if m.bias is not None:
            torch.nn.init.constant_(m.bias, 0)
    elif isinstance(m, torch.nn.BatchNorm2d):
        torch.nn.init.constant_(m.weight, 1)
        torch.nn.init.constant_(m.bias, 0)
    elif isinstance(m, torch.nn.Linear):
        torch.nn.init.xavier_normal_(m.weight, gain=0.02)
        if m.bias is not None:
            torch.nn.init.constant_(m.bias, 0)


def fixed_rtx3060_train():
    """í¬ê¸° ë¬¸ì œ í•´ê²°ëœ RTX 3060 í›ˆë ¨"""
    
    print("í¬ê¸° ë¬¸ì œ í•´ê²°ëœ RTX 3060 í›ˆë ¨ ì‹œì‘")
    
    # GPU ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ë””ë°”ì´ìŠ¤: {device}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        torch.backends.cudnn.benchmark = True
    
    # ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •
    image_size = 128  # 128x128ë¡œ í†µì¼
    
    # í¬ê¸°ê°€ ë§ëŠ” ëª¨ë¸ ìƒì„±
    model = VAEGANCompression(
        latent_dim=64,
        use_discriminator=False,
        quantization_method=None,
        base_channels=64,
        compression_ratio=8,
        target_size=image_size  # ëª©í‘œ í¬ê¸° ëª…ì‹œ
    ).to(device)
    
    # ì•ˆì •ì ì¸ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
    model.apply(initialize_weights)
    
    # í¬ê¸°ê°€ ë§ëŠ” transforms
    transforms = CompressionTransforms(image_size=(image_size, image_size), augment=False)
    dataset = CIFARDataset(
        cifar_type="cifar10",
        train=True,
        transforms=transforms.get_train_transforms()
    )
    
    # RTX 3060 ìµœì í™”ëœ ë°ì´í„°ë¡œë”
    dataloader = DataLoader(
        dataset, 
        batch_size=8,  # 128x128 ì´ë¯¸ì§€ë¡œ ë” í° ë°°ì¹˜ í¬ê¸°
        shuffle=True, 
        num_workers=4,
        pin_memory=True,
        persistent_workers=True
    )
    
    # ì˜µí‹°ë§ˆì´ì €
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=2e-4,
        weight_decay=1e-4,
        betas=(0.9, 0.999)
    )
    
    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=30, eta_min=1e-6
    )
    
    print(f"ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset):,}")
    print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
    print(f"ì´ë¯¸ì§€ í¬ê¸°: {image_size}x{image_size}")
    print(f"ë°°ì¹˜ í¬ê¸°: {dataloader.batch_size}")
    
    # Mixed precision scaler
    scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else None
    
    # í›ˆë ¨ ë£¨í”„
    model.train()
    best_psnr = 0.0
    
    for epoch in range(10):
        epoch_loss = 0.0
        epoch_psnr = 0.0
        num_batches = 0
        
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/10")
        
        for batch_idx, batch in enumerate(pbar):
            if batch_idx >= 50:  # 50ê°œ ë°°ì¹˜ë¡œ ì œí•œ
                break
                
            images = batch['image'].to(device, non_blocking=True)
            
            optimizer.zero_grad()
            
            try:
                # Mixed precision forward pass
                with torch.amp.autocast('cuda') if torch.cuda.is_available() else torch.no_grad():
                    results = model(images)
                    reconstructed = results['reconstructed']
                    mu = results['mu']
                    logvar = results['logvar']
                    
                    # í¬ê¸° í™•ì¸
                    if reconstructed.shape != images.shape:
                        print(f"í¬ê¸° ë¶ˆì¼ì¹˜: ì…ë ¥ {images.shape}, ì¶œë ¥ {reconstructed.shape}")
                        # ì¶œë ¥ì„ ì…ë ¥ í¬ê¸°ì— ë§ì¶¤
                        reconstructed = F.interpolate(
                            reconstructed, 
                            size=images.shape[2:], 
                            mode='bilinear', 
                            align_corners=False
                        )
                    
                    # ì•ˆì •ì ì¸ ì†ì‹¤ ê³„ì‚°
                    recon_loss = F.mse_loss(reconstructed, images)
                    
                    # KL divergence with numerical stability
                    kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
                    kl_loss = torch.clamp(kl_loss, min=0, max=10)
                    
                    total_loss = recon_loss + 0.0001 * kl_loss
                
                # NaN ì²´í¬
                if torch.isnan(total_loss) or torch.isinf(total_loss):
                    print(f"ë°°ì¹˜ {batch_idx}: NaN ê°ì§€, ê±´ë„ˆë›°ê¸°")
                    continue
                
                # Mixed precision backward pass
                if scaler:
                    scaler.scale(total_loss).backward()
                    scaler.unscale_(optimizer)
                    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    total_loss.backward()
                    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                    optimizer.step()
                
                # PSNR ê³„ì‚°
                with torch.no_grad():
                    mse = F.mse_loss(reconstructed, images)
                    if mse > 0 and not torch.isnan(mse):
                        psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
                        if not torch.isnan(psnr):
                            epoch_psnr += psnr.item()
                
                epoch_loss += total_loss.item()
                num_batches += 1
                
                pbar.set_postfix({
                    'Loss': f'{total_loss.item():.4f}',
                    'Recon': f'{recon_loss.item():.4f}',
                    'KL': f'{kl_loss.item():.6f}',
                    'PSNR': f'{psnr.item():.2f}' if 'psnr' in locals() and not torch.isnan(psnr) else 'N/A'
                })
                
                # ë©”ëª¨ë¦¬ ê´€ë¦¬
                if batch_idx % 10 == 0 and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    
            except Exception as e:
                print(f"ë°°ì¹˜ {batch_idx}ì—ì„œ ì˜¤ë¥˜: {e}")
                continue
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step()
        
        if num_batches > 0:
            avg_loss = epoch_loss / num_batches
            avg_psnr = epoch_psnr / num_batches if epoch_psnr > 0 else 0
            
            print(f"\nEpoch {epoch+1} ì™„ë£Œ:")
            print(f"  í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
            print(f"  í‰ê·  PSNR: {avg_psnr:.2f} dB")
            print(f"  í•™ìŠµë¥ : {optimizer.param_groups[0]['lr']:.6f}")
            
            if torch.cuda.is_available():
                memory_used = torch.cuda.memory_allocated() / 1024**3
                memory_cached = torch.cuda.memory_reserved() / 1024**3
                print(f"  GPU ë©”ëª¨ë¦¬: {memory_used:.1f}GB ì‚¬ìš© / {memory_cached:.1f}GB ìºì‹œ")
            
            # ìµœê³  ì„±ëŠ¥ ì €ì¥
            if avg_psnr > best_psnr:
                best_psnr = avg_psnr
                checkpoint_dir = Path("checkpoints/rtx3060")
                checkpoint_dir.mkdir(parents=True, exist_ok=True)
                
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'loss': avg_loss,
                    'psnr': avg_psnr,
                    'config': {
                        'latent_dim': 64,
                        'base_channels': 64,
                        'image_size': image_size
                    }
                }, checkpoint_dir / f"best_model_epoch_{epoch}.pth")
                print(f"  âœ“ ìƒˆë¡œìš´ ìµœê³  PSNR! ëª¨ë¸ ì €ì¥: {avg_psnr:.2f} dB")
    
    print(f"\nğŸš€ í›ˆë ¨ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœê³  PSNR: {best_psnr:.2f} dB")
    
    # ìµœì¢… í…ŒìŠ¤íŠ¸
    model.eval()
    with torch.no_grad():
        test_batch = next(iter(dataloader))
        test_images = test_batch['image'][:2].to(device)
        
        results = model(test_images)
        reconstructed = results['reconstructed']
        
        # í¬ê¸° ë§ì¶¤
        if reconstructed.shape != test_images.shape:
            reconstructed = F.interpolate(
                reconstructed, 
                size=test_images.shape[2:], 
                mode='bilinear', 
                align_corners=False
            )
        
        print(f"\nğŸ“ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   ì…ë ¥ í˜•íƒœ: {test_images.shape}")
        print(f"   ì¶œë ¥ í˜•íƒœ: {reconstructed.shape}")
        
        # ìµœì¢… í’ˆì§ˆ ì¸¡ì •
        mse = F.mse_loss(reconstructed, test_images)
        if mse > 0 and not torch.isnan(mse):
            psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
            print(f"   ìµœì¢… PSNR: {psnr:.2f} dB")
            
            # ì••ì¶•ë¥  ê³„ì‚°
            original_bits = test_images.numel() * 32  # float32
            compressed_bits = results['latent'].numel() * 8  # 8-bit estimate
            compression_ratio = original_bits / compressed_bits
            print(f"   ì¶”ì • ì••ì¶•ë¥ : {compression_ratio:.1f}:1")
        
        # RTX 3060 ì„±ëŠ¥ ìš”ì•½
        print(f"\nğŸ¯ RTX 3060 12GB ìµœì í™” ê²°ê³¼:")
        print(f"   âœ“ ì•ˆì •ì ì¸ í›ˆë ¨ ì™„ë£Œ")
        print(f"   âœ“ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì‚¬ìš© (12GB ë‚´)")
        print(f"   âœ“ Mixed precision í™œìš©")
        print(f"   âœ“ í¬ê¸° ë¬¸ì œ í•´ê²° ({image_size}x{image_size})")


if __name__ == "__main__":
    fixed_rtx3060_train()