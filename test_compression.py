#!/usr/bin/env python3
"""í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ì••ì¶•/ë³µì› ê²€ì¦"""

import torch
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path

# ëª¨ë¸ import
import sys
sys.path.append('.')
from scripts.minimal_rtx3060 import SimpleAutoEncoder

def test_compression():
    """ì••ì¶•/ë³µì› ê²€ì¦"""
    print("ğŸ” í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì••ì¶•/ë³µì› ê²€ì¦ ì‹œì‘")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ë””ë°”ì´ìŠ¤: {device}")
    
    # ëª¨ë¸ ë¡œë“œ
    model = SimpleAutoEncoder(latent_dim=64).to(device)
    
    checkpoint_path = "checkpoints/minimal/best_minimal_model.pth"
    if Path(checkpoint_path).exists():
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: PSNR {checkpoint['psnr']:.2f} dB")
    else:
        print("âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    test_dataset = datasets.CIFAR10(
        root='./data', 
        train=False, 
        download=True, 
        transform=transform
    )
    
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
    
    # ëª¨ë¸ í‰ê°€ ëª¨ë“œ
    model.eval()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    total_psnr = 0
    total_mse = 0
    num_batches = 0
    
    print("\nğŸ“Š ì••ì¶•/ë³µì› í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘...")
    
    with torch.no_grad():
        for batch_idx, (images, labels) in enumerate(test_loader):
            if batch_idx >= 10:  # 10ê°œ ë°°ì¹˜ë§Œ í…ŒìŠ¤íŠ¸
                break
                
            images = images.to(device)
            
            # ì••ì¶• (ì¸ì½”ë”©)
            latent = model.encoder(images)
            
            # ë³µì› (ë””ì½”ë”©)  
            reconstructed = model.decoder(latent)
            
            # ì„±ëŠ¥ ì¸¡ì •
            mse = F.mse_loss(reconstructed, images)
            psnr = 20 * torch.log10(2.0 / torch.sqrt(mse))
            
            total_psnr += psnr.item()
            total_mse += mse.item()
            num_batches += 1
            
            # ì²« ë²ˆì§¸ ë°°ì¹˜ ì‹œê°í™”
            if batch_idx == 0:
                save_comparison(images[:8], reconstructed[:8], labels[:8])
    
    # ê²°ê³¼ ì¶œë ¥
    avg_psnr = total_psnr / num_batches
    avg_mse = total_mse / num_batches
    
    print(f"\nğŸ¯ ì••ì¶•/ë³µì› ê²€ì¦ ê²°ê³¼:")
    print(f"   í‰ê·  PSNR: {avg_psnr:.2f} dB")
    print(f"   í‰ê·  MSE: {avg_mse:.6f}")
    print(f"   ì••ì¶•ë¥ : 768:1")
    
    # ì••ì¶• íš¨ìœ¨ì„± ê³„ì‚°
    original_size = 128 * 128 * 3 * 32  # 32bit float
    compressed_size = 64 * 32  # latent dimension * 32bit
    compression_ratio = original_size / compressed_size
    
    print(f"   ì‹¤ì œ ì••ì¶•ë¥ : {compression_ratio:.1f}:1")
    print(f"   ì›ë³¸ í¬ê¸°: {original_size/1024:.1f} KB")
    print(f"   ì••ì¶• í¬ê¸°: {compressed_size/1024:.1f} KB")

def save_comparison(originals, reconstructed, labels):
    """ì›ë³¸ê³¼ ì¬êµ¬ì„± ì´ë¯¸ì§€ ë¹„êµ ì €ì¥"""
    
    # CIFAR-10 í´ë˜ìŠ¤ëª…
    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
               'dog', 'frog', 'horse', 'ship', 'truck']
    
    # ì •ê·œí™” í•´ì œ ([-1,1] -> [0,1])
    originals = (originals + 1) / 2
    reconstructed = (reconstructed + 1) / 2
    
    # í´ë¨í•‘
    originals = torch.clamp(originals, 0, 1)
    reconstructed = torch.clamp(reconstructed, 0, 1)
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(2, 8, figsize=(16, 4))
    fig.suptitle('ì••ì¶•/ë³µì› ê²€ì¦ ê²°ê³¼ (ìœ„: ì›ë³¸, ì•„ë˜: ë³µì›)', fontsize=14)
    
    for i in range(8):
        # ì›ë³¸ ì´ë¯¸ì§€
        orig_img = originals[i].cpu().permute(1, 2, 0).numpy()
        axes[0, i].imshow(orig_img)
        axes[0, i].set_title(f'{classes[labels[i]]}', fontsize=10)
        axes[0, i].axis('off')
        
        # ë³µì› ì´ë¯¸ì§€
        recon_img = reconstructed[i].cpu().permute(1, 2, 0).numpy()
        axes[1, i].imshow(recon_img)
        
        # PSNR ê³„ì‚°
        mse = F.mse_loss(reconstructed[i], originals[i])
        psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
        axes[1, i].set_title(f'PSNR: {psnr:.1f}dB', fontsize=10)
        axes[1, i].axis('off')
    
    plt.tight_layout()
    plt.savefig('compression_test_results.png', dpi=150, bbox_inches='tight')
    print("ğŸ–¼ï¸  ë¹„êµ ì´ë¯¸ì§€ ì €ì¥: compression_test_results.png")

if __name__ == "__main__":
    test_compression()