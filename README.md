# ğŸš€ Neural Compression

**RTX 3060 ìµœì í™”ëœ ê³ ê¸‰ ë”¥ëŸ¬ë‹ ì••ì¶• ëª¨ë¸** - VAE-GAN í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/CUDA-11.8+-green.svg)](https://developer.nvidia.com/cuda-downloads)

## âœ¨ ì£¼ìš” íŠ¹ì§•

- **ğŸ§  í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜**: VAE + GAN + Multi-Head Attention ê²°í•©
- **âš¡ RTX 3060 ìµœì í™”**: 12GB GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í™œìš©
- **ğŸ¯ ê³ ê¸‰ ì–‘ìí™”**: Vector Quantization + Learned Quantization
- **ğŸ“Š ì†ì‹¤ í•¨ìˆ˜ ìµœì í™”**: Perceptual + Rate-Distortion + MS-SSIM Loss
- **ğŸ”§ Mixed Precision**: FP16 í›ˆë ¨ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë° ì†ë„ ìµœì í™”
- **ğŸ“ˆ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: TensorBoard + WandB ì§€ì›

## ğŸ› ï¸ ì„¤ì¹˜

### ì „ì œ ì¡°ê±´
- Python 3.8+
- CUDA 11.8+ (RTX 3060 ìµœì í™”)
- 12GB+ GPU ë©”ëª¨ë¦¬

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/TechieQuokka/neural-compression.git
cd neural-compression

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
pip install -e .
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### RTX 3060 ìµœì í™” í›ˆë ¨
```bash
# RTX 3060 12GB ìµœì í™”ëœ ì•ˆì •ì ì¸ í›ˆë ¨
python scripts/minimal_rtx3060.py

# ê³ ê¸‰ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨ (Hydra ê¸°ë°˜)
python scripts/train.py --config-name=rtx3060_config
```

### ëª¨ë¸ ì‚¬ìš©
```python
from neural_compression.models.vae_gan_compression import VAEGANCompression
import torch

# RTX 3060 ìµœì í™” ëª¨ë¸ ìƒì„±
model = VAEGANCompression(
    latent_dim=64,
    use_discriminator=False,
    base_channels=64,
    target_size=128
)

# ì´ë¯¸ì§€ ì••ì¶• ë° ë³µì›
with torch.no_grad():
    results = model(images)
    compressed = results['latent']
    reconstructed = results['reconstructed']
```

## ğŸ“Š ì„±ëŠ¥ ê²°ê³¼

### RTX 3060 12GB ìµœì í™” ê²°ê³¼
- **PSNR**: 19.09 dB
- **ì••ì¶•ë¥ **: 768:1
- **GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: 0.1GB / 12GB
- **í›ˆë ¨ ì†ë„**: ~30 it/s (ë°°ì¹˜ í¬ê¸° 16)

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
neural-compression/
â”œâ”€â”€ src/neural_compression/
â”‚   â”œâ”€â”€ models/              # ğŸ§  ì‹ ê²½ë§ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ vae_gan_compression.py    # ë©”ì¸ VAE-GAN ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ encoder.py               # ResNet ê¸°ë°˜ ì¸ì½”ë”
â”‚   â”‚   â”œâ”€â”€ decoder.py               # íŠ¸ëœìŠ¤í¬ì¦ˆ ì»¨ë³¼ë£¨ì…˜ ë””ì½”ë”
â”‚   â”‚   â”œâ”€â”€ attention.py             # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
â”‚   â”‚   â”œâ”€â”€ quantization.py          # ì–‘ìí™” ë°©ë²•ë“¤
â”‚   â”‚   â””â”€â”€ discriminator.py         # PatchGAN íŒë³„ê¸°
â”‚   â”œâ”€â”€ losses/              # ğŸ“Š ì†ì‹¤ í•¨ìˆ˜
â”‚   â”‚   â”œâ”€â”€ combined.py              # ê²°í•©ëœ ì†ì‹¤ í•¨ìˆ˜
â”‚   â”‚   â”œâ”€â”€ reconstruction.py        # ì¬êµ¬ì„± ì†ì‹¤
â”‚   â”‚   â”œâ”€â”€ compression.py           # ì••ì¶• íŠ¹í™” ì†ì‹¤
â”‚   â”‚   â””â”€â”€ adversarial.py           # ì ëŒ€ì  ì†ì‹¤
â”‚   â”œâ”€â”€ training/            # ğŸ¯ í›ˆë ¨ ë¡œì§
â”‚   â”‚   â””â”€â”€ lightning_module.py      # PyTorch Lightning ëª¨ë“ˆ
â”‚   â””â”€â”€ utils/               # ğŸ› ï¸ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ configs/                 # âš™ï¸ Hydra ì„¤ì •
â”‚   â”œâ”€â”€ rtx3060_config.yaml          # RTX 3060 ìµœì í™” ì„¤ì •
â”‚   â””â”€â”€ config.yaml                  # ê¸°ë³¸ ì„¤ì •
â”œâ”€â”€ scripts/                 # ğŸ“ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ minimal_rtx3060.py           # âœ… ì•ˆì •ì ì¸ RTX 3060 í›ˆë ¨
â”‚   â”œâ”€â”€ train.py                     # Hydra ê¸°ë°˜ í›ˆë ¨
â”‚   â””â”€â”€ prepare_data.py              # ë°ì´í„° ì¤€ë¹„
â”œâ”€â”€ docs/                    # ğŸ“š ë¬¸ì„œ
â”‚   â””â”€â”€ architecture.md              # ì•„í‚¤í…ì²˜ ì„¤ê³„ ë¬¸ì„œ
â””â”€â”€ *.png                    # ğŸ“ˆ í›ˆë ¨ ê²°ê³¼ ë° ë¹„êµ ì´ë¯¸ì§€
```

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ê°œìš”

### VAE-GAN í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
```
Input Image (128Ã—128) 
    â†“
ğŸ”„ ResNet Encoder + CBAM Attention
    â†“
ğŸ“¦ Vector Quantization (64D latent)
    â†“
ğŸ”„ Transpose Conv Decoder + Self-Attention
    â†“
Output Image (128Ã—128)
```

### í•µì‹¬ êµ¬ì„± ìš”ì†Œ
1. **ì¸ì½”ë”**: ResNet ë°±ë³¸ + CBAM ì–´í…ì…˜
2. **ì–‘ìí™”**: ë²¡í„° ì–‘ìí™”ë¡œ ì••ì¶•ë¥  í–¥ìƒ
3. **ë””ì½”ë”**: 6ë‹¨ê³„ ì—…ìƒ˜í”Œë§ + ì…€í”„ ì–´í…ì…˜
4. **ì†ì‹¤ í•¨ìˆ˜**: MSE + KL Divergence + Perceptual Loss

## ğŸ¯ RTX 3060 íŠ¹í™” ìµœì í™”

### ë©”ëª¨ë¦¬ ìµœì í™”
- **Mixed Precision (FP16)**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 50% ì ˆê°
- **Gradient Checkpointing**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°±í”„ë¡­
- **ë°°ì¹˜ í¬ê¸° ìµœì í™”**: 16 (12GB GPU ìµœì )

### ì„±ëŠ¥ ìµœì í™”
- **CUDA ìµœì í™”**: `torch.backends.cudnn.benchmark = True`
- **TensorFloat-32**: `allow_tf32 = True`
- **Pin Memory**: ë¹ ë¥¸ GPU ì „ì†¡
- **Persistent Workers**: ë©€í‹°í”„ë¡œì„¸ì‹± ìµœì í™”

## ğŸ”§ ì‚¬ìš©ë²•

### 1ï¸âƒ£ ë¹ ë¥¸ í›ˆë ¨ (ì¶”ì²œ)
```bash
# RTX 3060 ìµœì í™”ëœ ì•ˆì •ì ì¸ í›ˆë ¨
python scripts/minimal_rtx3060.py
```

### 2ï¸âƒ£ ê³ ê¸‰ ì„¤ì • í›ˆë ¨
```bash
# Hydra ì„¤ì •ìœ¼ë¡œ ì»¤ìŠ¤í„°ë§ˆì´ì§•
python scripts/train.py --config-name=rtx3060_config

# ë°°ì¹˜ í¬ê¸° ì¡°ì •
python scripts/train.py data.batch_size=8 training.max_epochs=50
```

### 3ï¸âƒ£ ëª¨ë¸ ë¡œë“œ ë° ì‚¬ìš©
```python
import torch
from neural_compression.models.vae_gan_compression import VAEGANCompression

# í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
checkpoint = torch.load('checkpoints/minimal/best_minimal_model.pth')
model = VAEGANCompression(latent_dim=64, target_size=128)
model.load_state_dict(checkpoint['model_state_dict'])

# ì••ì¶• ë° ë³µì›
model.eval()
with torch.no_grad():
    results = model(input_images)
    compressed_latent = results['latent']
    reconstructed_images = results['reconstructed']
```

## ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼

### í›ˆë ¨ ì„±ê³¼ (RTX 3060 12GB)
| ë©”íŠ¸ë¦­ | ê°’ |
|--------|-----|
| **ìµœê³  PSNR** | 19.09 dB |
| **ì••ì¶•ë¥ ** | 768:1 |
| **GPU ë©”ëª¨ë¦¬** | 0.1GB / 12GB |
| **í›ˆë ¨ ì†ë„** | 30+ it/s |
| **ì•ˆì •ì„±** | âœ… NaN ì—†ìŒ |

### ëª¨ë¸ ì‚¬ì–‘
- **íŒŒë¼ë¯¸í„° ìˆ˜**: 1.9M (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
- **Latent Dimension**: 64
- **ì…ë ¥ í¬ê¸°**: 128Ã—128Ã—3
- **ì••ì¶• ë¹„ìœ¨**: 16:1

## ğŸ¨ ê²°ê³¼ ì´ë¯¸ì§€

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ ì´ë¯¸ì§€ íŒŒì¼ë“¤:
- `minimal_reconstruction_comparison.png`: ì›ë³¸ vs ì¬êµ¬ì„± ë¹„êµ
- `minimal_rtx3060_results.png`: í›ˆë ¨ ì†ì‹¤ ë° PSNR ê·¸ë˜í”„

## âš¡ ì„±ëŠ¥ ìµœì í™” íŒ

### RTX 3060 ì‚¬ìš©ì
```bash
# ìµœì  ì„¤ì •ìœ¼ë¡œ í›ˆë ¨
export CUDA_VISIBLE_DEVICES=0
python scripts/minimal_rtx3060.py
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
```yaml
# configs/rtx3060_config.yaml ìˆ˜ì •
data:
  batch_size: 8      # 16 â†’ 8ë¡œ ì¶•ì†Œ
  image_size: [64, 64]  # 128 â†’ 64ë¡œ ì¶•ì†Œ
```

## ğŸ† ì£¼ìš” ì„±ê³¼

- âœ… **í¬ê¸° ë¬¸ì œ í•´ê²°**: ì…ì¶œë ¥ í¬ê¸° ì¼ì¹˜ ë³´ì¥
- âœ… **ì•ˆì •ì ì¸ í›ˆë ¨**: NaN/Inf ë¬¸ì œ í•´ê²°
- âœ… **RTX 3060 ìµœì í™”**: 12GB ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í™œìš©
- âœ… **Mixed Precision**: FP16ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
- âœ… **ì‹¤ìš©ì ì¸ ì••ì¶•ë¥ **: 768:1 ë‹¬ì„±

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [ì•„í‚¤í…ì²˜ ì„¤ê³„](docs/architecture.md): ìƒì„¸í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ëª…
- [Hydra ì„¤ì •](configs/): í›ˆë ¨ ì„¤ì • íŒŒì¼ë“¤

## ğŸ¤ ê¸°ì—¬

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

MIT License - ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ ì°¸ì¡°